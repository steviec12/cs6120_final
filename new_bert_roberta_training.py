# -*- coding: utf-8 -*-
"""new_bert_roberta_training.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o5pkcP-a8zazWLSX5UukHquflDrSHiGv
"""

"""import pandas as pd
from sklearn.model_selection import train_test_split

# 1. Load the original data
df = pd.read_csv('train.csv')

# 2. Perform the split (Fixed Random State = 42)
train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# 3. Save to disk
train_df.to_csv('new_train.csv', index=False)
test_df.to_csv('new_test.csv', index=False)

print(f"Split completed")
print(f"New Train size: {len(train_df)}")
print(f"New Test size:  {len(test_df)}")"""

"""
CS 6120 Final Project: Deep Learning Humor Prediction
-----------------------------------------------------
Authors: Yuang Chen, Hao Ding, Abulajiang Abulamu
Task: Subtask 1 - Humor Regression (Funniness Estimation)
Models: BERT (bert-base-uncased) and RoBERTa (roberta-base)

Description:
This script performs the following:
1. Loads PRE-SPLIT datasets (new_train.csv and new_test.csv).
2. Performs a Grid Search to fine-tune BERT and RoBERTa models.
3. Selects the best model based on Mean Absolute Error (MAE).
4. Retrains the best model configuration.
5. Generates predictions for the development set for error analysis.
"""

import pandas as pd
import numpy as np
import torch
import random
import re
import os
import gc
from sklearn.metrics import mean_absolute_error
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer
)
from datasets import Dataset


# 1. CONFIGURATION & HYPERPARAMETERS

SEED = 42
MODELS_TO_TEST = ['roberta-base', 'bert-base-uncased']
LEARNING_RATES = [2e-5, 3e-5, 5e-5]
BATCH_SIZE = 32
EPOCHS = 5
MAX_LEN = 128

# File Paths

TRAIN_PATH = 'data/new_train.csv'
VAL_PATH = 'data/new_test.csv'
DEV_PATH = 'data/dev.csv'

OUTPUT_DIR = './model_outputs'
PREDICTION_FILE = 'dev_predictions.csv'


# 2. UTILITY FUNCTIONS


def set_seed(seed_value=42):
    """Sets the seed for reproducibility across runs."""
    random.seed(seed_value)
    np.random.seed(seed_value)
    torch.manual_seed(seed_value)
    torch.cuda.manual_seed_all(seed_value)

def preprocess_text(df):
    """
    Combines context for the model by inserting the edit word into the sentence structure.
    Replaces <original> with the edited word.
    """
    return df.apply(lambda x: re.sub(r'<.+?>', x['edit'], x['original']), axis=1)

def load_data(filepath, is_train=True):
    """Loads and preprocesses data from CSV."""
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"File not found: {filepath}")

    df = pd.read_csv(filepath)
    df['text'] = preprocess_text(df)

    # Both train and val (new_test) should have labels
    if is_train and 'meanGrade' in df.columns:
        df['label'] = df['meanGrade']

    return df

def compute_metrics(eval_pred):
    """Custom metric for regression: Mean Absolute Error (MAE)."""
    predictions, labels = eval_pred
    predictions = predictions.flatten()
    # Clamp predictions to valid 0-3 range
    predictions = np.clip(predictions, 0.0, 3.0)
    mae = mean_absolute_error(labels, predictions)
    return {"mae": mae}

def tokenize_function(examples, tokenizer):
    """Tokenizes text data."""
    return tokenizer(
        examples['text'],
        padding="max_length",
        truncation=True,
        max_length=MAX_LEN
    )


# 3. MAIN EXECUTION


def main():
    # Set device and seed
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")
    set_seed(SEED)

    # 1. Data Loading (Pre-split)
    print("\n[1/5] Loading Data...")

    # Load Training Data
    print(f"Loading Training Set from {TRAIN_PATH}...")
    train_df = load_data(TRAIN_PATH, is_train=True)

    # Load Validation Data (Your 'new_test.csv')
    print(f"Loading Validation Set from {VAL_PATH}...")
    val_df = load_data(VAL_PATH, is_train=True)

    # Convert to Hugging Face Dataset objects
    hf_train_raw = Dataset.from_pandas(train_df)
    hf_val_raw = Dataset.from_pandas(val_df)

    # 2. Grid Search
    print("\n[2/5] Starting Hyperparameter Grid Search...")
    results_log = []

    for model_name in MODELS_TO_TEST:
        print(f"\n>>> Evaluating Model Architecture: {model_name}")

        # Load tokenizer for specific model
        tokenizer = AutoTokenizer.from_pretrained(model_name)

        # Apply tokenization
        tokenized_train = hf_train_raw.map(lambda x: tokenize_function(x, tokenizer), batched=True)
        tokenized_val = hf_val_raw.map(lambda x: tokenize_function(x, tokenizer), batched=True)

        for lr in LEARNING_RATES:
            print(f"   Training with LR={lr}...")

            model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1).to(device)

            args = TrainingArguments(
                output_dir=f"{OUTPUT_DIR}/temp_{model_name}_{lr}",
                learning_rate=lr,
                per_device_train_batch_size=BATCH_SIZE,
                per_device_eval_batch_size=BATCH_SIZE,
                num_train_epochs=EPOCHS,
                weight_decay=0.01,
                eval_strategy="epoch",
                save_strategy="epoch",
                load_best_model_at_end=True,
                metric_for_best_model="mae",
                greater_is_better=False,
                report_to="none",
                fp16=torch.cuda.is_available()
            )

            trainer = Trainer(
                model=model,
                args=args,
                train_dataset=tokenized_train,
                eval_dataset=tokenized_val,
                processing_class=tokenizer,
                compute_metrics=compute_metrics
            )

            trainer.train()
            metrics = trainer.evaluate()
            final_mae = metrics['eval_mae']

            print(f"   -> MAE: {final_mae:.4f}")
            results_log.append({'Model': model_name, 'LR': lr, 'MAE': final_mae})

            # Cleanup
            del model, trainer
            torch.cuda.empty_cache()
            gc.collect()

    # 3. Select Best Model
    print("\n[3/5] Analyzing Results...")
    results_df = pd.DataFrame(results_log).sort_values(by='MAE', ascending=True)
    print("\n--- Leaderboard ---")
    print(results_df)

    best_run = results_df.iloc[0]
    print(f"\n WINNER: {best_run['Model']} with LR={best_run['LR']} (MAE: {best_run['MAE']:.4f})")

    # 4. Retrain Best Model
    print(f"\n[4/5] Retraining Best Model ({best_run['Model']}) for Final Output...")
    final_model_name = best_run['Model']
    final_lr = best_run['LR']

    tokenizer = AutoTokenizer.from_pretrained(final_model_name)
    model = AutoModelForSequenceClassification.from_pretrained(final_model_name, num_labels=1).to(device)

    # Re-tokenize with the winner's tokenizer
    tokenized_train = hf_train_raw.map(lambda x: tokenize_function(x, tokenizer), batched=True)
    tokenized_val = hf_val_raw.map(lambda x: tokenize_function(x, tokenizer), batched=True)

    final_args = TrainingArguments(
        output_dir=f"{OUTPUT_DIR}/final_best_model",
        learning_rate=final_lr,
        per_device_train_batch_size=BATCH_SIZE,
        num_train_epochs=EPOCHS,
        weight_decay=0.01,
        save_strategy="no",
        report_to="none",
        fp16=torch.cuda.is_available()
    )

    trainer = Trainer(
        model=model,
        args=final_args,
        train_dataset=tokenized_train,
        eval_dataset=tokenized_val,
        processing_class=tokenizer
    )

    trainer.train()

    # Save the final model artifacts (for potential grading/reuse)
    print("Saving final model artifacts...")
    trainer.save_model(f"{OUTPUT_DIR}/final_best_model")
    tokenizer.save_pretrained(f"{OUTPUT_DIR}/final_best_model")

    # 5. Generate Predictions on Official Dev Set
    print(f"\n[5/5] Generating predictions on {DEV_PATH}...")
    if os.path.exists(DEV_PATH):
        df_dev = load_data(DEV_PATH, is_train=False)
        hf_dev = Dataset.from_pandas(df_dev)
        tokenized_dev = hf_dev.map(lambda x: tokenize_function(x, tokenizer), batched=True)

        predictions = trainer.predict(tokenized_dev)
        preds = np.clip(predictions.predictions.flatten(), 0.0, 3.0)

        df_dev['predicted_funniness'] = preds
        df_dev[['id', 'original', 'edit', 'predicted_funniness']].to_csv(PREDICTION_FILE, index=False)
        print(f"Success! Predictions saved to {PREDICTION_FILE}")
    else:
        print(f"Warning: {DEV_PATH} not found. Skipping predictions.")

if __name__ == "__main__":
    main()
